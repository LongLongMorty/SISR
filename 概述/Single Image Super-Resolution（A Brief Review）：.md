### Single Image Super-Resolution（A Brief Review）：

[TOC]

### 背景知识

#### 单图像超分辨率（SISR）和多图像超分辨率（MISR）

**单图像超分辨率 (SISR)**:

- **定义**: SISR是从单一的低分辨率图像中恢复出高分辨率图像。
- **方法**: 通常使用插值方法（如双线性、双三次或$Lanczos$插值）或深度学习方法（如卷积神经网络或生成对抗网络）。
- **应用**: SISR常用于图像和视频增强，如将老旧的电影转换为高清版本或增强数字摄像机拍摄的图像。
- **挑战**: 由于只有一个低分辨率图像作为参考，SISR面临的主要挑战是恢复图像中的**细节和纹理**。



**多图像超分辨率 (MISR)**:

- **定义**: MISR是从多个低分辨率图像中恢复出一个高分辨率图像。这些低分辨率图像通常是同一场景的不同视图或在不同时间拍摄的。
- **方法**: 常用的方法包括基于投影的方法、基于频域的方法和基于学习的方法。
- **应用**: MISR常用于卫星图像、医学成像和摄像头阵列中，其中可以从多个角度或多个时间点获得同一场景的图像。
- **优势**: 由于有多个图像作为参考，MISR可以更有效地恢复图像中的细节和纹理。

- **挑战**: MISR的主要挑战是图像对齐和融合，因为从不同视角或时间点拍摄的图像可能存在微小的差异或运动模糊。

### 一、论文主要讨论

#### **1.The exploration of efficient neural network architectures for SISR .(探索 SISR 的高效神经网络架构)**

#### **2.the development of effective optimization objectives for deep SISR learning.(为深度 SISR 学习制定有效的优化目标)**

### 二、背景(SISR常用的算法)

SISR常用的三种算法：

#### **1.interpolation-based methods：**

非常速度简单，但存在准确性缺陷。

#### **2.reconstruction-based methods ：**

采用复杂的先验知识来限制可能的解空间，目的是生成灵活和清晰的细节。然而，当比例因子增加时，许多基于重构的方法的性能会迅速下降，这些方法通常很耗时。

##### **正则化方法**:

- 这类方法通过建立一个数学模型来描述低分辨率和高分辨率图像之间的关系，并添加一个正则化项来约束高分辨率图像的复杂性。
- 常见的正则化技术包括Tikhonov正则化、全变分正则化等。
- 正则化方法可以更好地恢复图像的细节，但计算成本较高。

##### **基于稀疏表示的方法**:

- 这些方法的核心思想是图像的高频细节可以使用一个预先训练的字典进行稀疏表示。
- 通过优化问题，可以从低分辨率图像中恢复出这些高频细节。
- 这类方法通常能够更好地恢复图像的纹理和细节。

##### **自相似性方法**:

- 这类方法基于图像中的自相似性，即图像的不同部分可能有相似的结构和纹理。
- 通过搜索图像中的重复模式，可以从低分辨率图像中恢复出高分辨率的细节。

##### **观测模型方法**:

- 这类方法基于观测模型，例如模糊、下采样等，来建立低分辨率和高分辨率图像之间的关系。
- 通过反转这些模型，可以从低分辨率图像中恢复高分辨率图像

#### **3.learning-based methods.**

- 马尔可夫随机场（MRF）

- Neighbor embedding 方法

- 受稀疏信号恢复理论的启发，稀疏编码方法应用于 SISR 问题

- 随机森林

- **基于 DL 的 SISR 算法显示出比基于重建和其他基于学习的方法更优越的性能**：

  人工神经网络(ANN)

  卷积神经网络 (CNN) [35] 和循环神经网络 (RNN)

  受限玻尔兹曼机 (RBM) 

  预训练深度神经网络 (DNN)

  基于 DNN 的无监督算法，例如深度玻尔兹曼机 (DBM) 、变分自动编码器 (VAE)  和生成对抗网络 (GAN) 

### 三、SISR的深度架构

**讨论多种架构，超分辨率CNN (SRCNN)的网络架构为基准**

#### 1.基准SRCNN

SRCNN算法：首个使用基于深度学习的端到端的超分辨率算法，效果好

 

<img src=" C:\Users\Morty\AppData\Roaming\Typora\typora-user-images\image-20230717163721402.png" width="600" height="450">

使用损失函数：

**均方误差（MSE）**

算法流程：

1.考虑单个低分辨率图像。我们首先**使用双三次插值将其扩展到所需的大小**（此时还是低分辨率图像）；

2.三层卷积网络层拟合非线性操作

第一层：**Patch extraction and representation**（图像块的提取与特征表示）

输入：低分辨率图像

卷积核：c × f1 × f1 × n1，其中 c 是输入图像中的通道数，f1 是过滤器的空间大小

输出：n1个feature maps of low-resolution image

第二层：**Non-linear mapping**（特征非线性映射）：非线性映射：该操作将每个高维向量非线性地映射到另一个高维向量上。每个映射向量在概念上都是一个高分辨率补丁的表示。这些向量组成另一组特征图;

输入：n1个feature maps of low-resolution image

卷积核： n1 × 1 × 1 × n2

输出：n2 feature maps of high-resolution image

第三层：**Reconstruction**（重建为高分辨率图像)

输入：n2 feature maps of high-resolution image

卷积核：n2 × f3 × f3 × c

输出：HR图像

![image-20230717165132428](C:\Users\Morty\AppData\Roaming\Typora\typora-user-images\image-20230717165132428.png)

#### 2.最先进的深度SISR网络

##### 1.基于SRCNN，从上采样方法改进

###### **FSRCNN:**

SRCNN缺点：高计算成本仍然阻碍了它的实际使用，处理速度太慢

SRCNN的两个限制条件（**two inherent limitations**）：

1.作为预处理步骤，原始的LR图像需要使用双三次插值上采样到所需的大小以形成输入图像。

2.第二个限制在于昂贵的非线性映射步骤。

FSRCNN改进方向：

1.adopt a deconvolution layer to replace the bicubic interpolation（采用反卷积层代替双三次插值），we place the deconvolution layer1 at the end of the network, then the computational complexity is only proportional to the spatial size of the original LR image. （我们将反卷积层放置在网络的末端，那么计算复杂度只与原始LR图像的空间大小成正比。）

2.我们在映射层的开头和结尾分别添加了缩小层和扩展层，以限制在低维特征空间中的映射。此外，我们将单个宽映射层分解为多个带有固定滤波器大小3×3的层。

FSRCNN详细介绍:

![img](https://pic4.zhimg.com/v2-c6b77086f36fe4d26f574e2fb9c17233_r.jpg)

（该图显示了SRCNN和FSRCNN的网络结构。所提出的 FSRCNN 主要从三个方面与 SRCNN 不同。首先，FSRCNN采用原始的低分辨率图像作为输入，无需双三次插值。在网络的末端引入了一个反卷积层来执行上采样。其次，SRCNN 中的非线性映射步骤被 FSRCNN 中的三个步骤所取代，即收缩、映射和扩展步骤。第三，FSRCNN 采用更小的滤波器尺寸和更深的网络结构。这些改进为 FSRCNN 提供了更好的性能，但计算成本低于 SRCNN。）

FSRCNN可以分解为特征提取、收缩、映射、扩展和反卷积五个部分。其中前四部分都是卷积层conv（fi,ni,ci），第五部分是去卷积层deconv（fi,ni,ci），其中fi,ni,ci分别为核尺寸，核数量，核通道。作者将网络中的变量分为敏感变量和不敏感变量（敏感是指微小改变即可对网络结果造成很大影响。），其中不敏感变量可以预设，而敏感变量则需根据实验比较得出其值。

第一部分：Feature extraction（特征提取）:

这部分是和SRCNN相似的，不同点在于FSRCNN不经过对LR图像的插值，而是直接从LR图像提取子图块信息。参照SRCNN中插值后的提取块的大小为**9X9**，对应插值前的LR的块大小为**5X5**，因此，FSRCNN提取的块为**5X5**大小的。若输入图像为灰度，则核深度为1，而核的数量决定了该层卷积输出的特征图的维度d。因为经过特征提取部分的特征图即将送入真正的SR过程，所以维度d是至关重要的。因此**d是第一个敏感变量**，需要实验对比得出。因此该层可记为**conv（5，d，1）**。

第二部分：Shrinking（压缩，**高低维指的是特征图的通道数**）：

这部分主要考虑到SRCNN中直接在高维特征图上对LR做SR，因此会通过增加滤波核的通道数和数量来增加参数（计算量）。因此，考虑如下思路：先对LR图像通道数进行减小，然后在低维LR特征图进行SR操作，这样会减少运算参数，最后再对生成的SR图像进行升维操作。

我们可以用s个1X1的滤波核，对来自特征提取层的d维图像进行降维处理（从d降到s），**s是第二个敏感变量**，这可以为后续的SR操作减少参数量。该层可记为**conv（1，s，d）**。

第三部分：Non-linear mapping（非线性映射）

首先，作为性能和网络规模之间的权衡，我们采用中等滤波器大小f3 = 3。然后，为了保持与SRCNN相同的良好性能，我们使用多个3 × 3层来替换单个宽层。映射层数是另一个敏感变量**（表示为 m）**，它决定了映射精度和复杂性。为了保持一致，所有映射层都包含相同数量的过滤器 n3 = s。那么非线性映射部分可以表示为 **m × Conv(3, s, s)**。

第四部分：Expanding（扩展）

扩展层就像收缩层的逆过程。出于计算效率，收缩操作减少了 LR 特征维度的数量。然而，如果我们直接从这些低维特征生成 HR 图像，最终的恢复质量将很差。因此，我们在映射部分之后添加了一个扩展层来扩展 HR 特征维度。为了与收缩层保持一致，我们还采用了 **1×1** 滤波器，其数量与 LR 特征提取层相同。与收缩层 **Conv(1, s, d)** 不同，扩展层是 **Conv(1, d, s)**。

第五部分：Deconvolution（反卷积）

可视为卷积的逆操作，可以将小尺寸的图像恢复成大尺寸的图像。参照图4，我们通过在deconv前移动一个步长，得到deconv后移动的两个步长的区域，这样就可以实现对图像放大2倍的操作了。作者也提供了另一种看待此网络的角度，即将信息视为从HR向LR传播。这样可以更方便理解。同时为了保持对称结构，需要采取**9X9**的滤波器大小。该层可记为**deconv（9，1，d）**。去卷积不同于传统的插值方法，传统的方法对所有的重建像素都有一套共同的重建公式，而去卷积的核需要学习得到，它能够针对具体的任务，得出更精确的结果。

激活函数：

参数整流线性单元 (**PReLU**)：在原来relu 的基础上，对负半轴的梯度也能激活（即使很小），消除了部分梯度无法激活的情况。

损失函数：

**均方误差MSE**



###### **ESPCN**

ESPCN的基本结构如下：

1. **特征提取层**: 这是网络的第一个卷积层，用于从输入的低分辨率图像中提取有用的特征。

2. **非线性映射层**: 在特征提取之后，网络有一个或多个卷积层来执行非线性映射。这些层的目的是增强从低分辨率图像中提取的特征。

3. **亚像素卷积层 (Sub-pixel Convolutional Layer)**: 这是ESPCN的核心。与传统的上采样方法不同，亚像素卷积层通过重新排列特征图中的像素来实现上采样。这种方法被称为“像素洗牌”或“亚像素卷积”，它可以有效地将低分辨率的特征图转换为高分辨率的输出。

   

![img](C:\Users\Morty\Downloads\屏幕截图 2023-09-22 192149.png)

##### 2.加深网络结构

###### **VDSR**

如其名字所示，VDSR是一个非常深的网络，通常包含20个卷积层。这使得VDSR能够捕获更复杂的图像特征。

1. **训练策略**：
   - **SRCNN**：SRCNN是端到端地训练的，直接从低分辨率图像到高分辨率图像。
   - **VDSR**：VDSR采用残差学习策略，它预测的是低分辨率和高分辨率图像之间的残差。这种策略使得网络可以更容易地学习到恒等映射，从而加速收敛并提高性能。
2. **上采样方法**：
   - **SRCNN**：首先使用传统的插值方法将低分辨率图像上采样到目标分辨率，然后通过网络进行处理。
   - **VDSR**：VDSR直接在低分辨率空间中进行计算，然后使用一个简单的插值方法进行上采样。网络预测的残差与上采样后的图像相加，得到最终的高分辨率图像。
3. **性能**：
   - 由于其深度和残差学习策略，**VDSR**在多个基准数据集上都表现出比SRCNN更好的性能。
4. **计算复杂性**：
   - 虽然**VDSR**的网络结构更深，但由于其残差学习策略，它的计算复杂性与**SRCNN**相当。

 

![img](C:\Users\Morty\Downloads\论文配图.png)

整个结构可以分为以下几个部分：

第一部分：

**上采样**

低分辨率的输入图像通过一个传统的插值方法（例如双三次插值）被上采样到目标的高分辨率。

第二部分：

上采样的图像被送入VDSR网络（20层卷积网络），网络预测出一个残差图像

**第三部分**

这个**预测**的残差图像与上采样的图像相加，得到最终的高分辨率输出图像。



**总的来说，VDSR的主要优势在于其深度和残差学习策略，这使得它在图像质量上优于SRCNN。然而，由于其深度，VDSR需要更多的训练数据和更长的训练时间。**（这种残差学习策略的优势在于，网络只需要学习低分辨率和高分辨率图像之间的差异（即残差），而不是直接学习高分辨率图像。这使得网络可以更容易地学习到恒等映射，从而加速收敛并提高性能。）

###### **DRCN**

DRCN 结构：

1. **Embedding Network**：它首先接收一个低分辨率的图像作为输入，并输出一个特征表示。

2. **Recursive Network**：接着，这个特征表示被送入递归网络。在递归网络中，这个特征表示被多次递归地处理，每次都学习和更新残差信息。这意味着，递归网络的每一次迭代都在更新和细化其超分辨率预测。

3. **Reconstruction Network**：最后，递归网络的输出（经过多次迭代后的特征表示）被送入重建网络，与原始的低分辨率图像相加，然后进行上采样，以产生高分辨率的输出。

   ![img](C:\Users\Morty\Downloads\论文配图2.png)

DRCN 的特点：

- **递归 vs. 深度**：尽管 DRCN 使用了递归的结构，但它在实际上是一个非常深的网络，因为它在多个递归步骤中重复使用了卷积层。
- **参数效率**：由于权重共享，DRCN 的参数数量远少于传统的深度卷积网络。这使得 DRCN 在有限的计算资源下更为高效。
- **嵌套的残差学习**：DRCN 的一个关键特点是它在每个递归步骤中都学习残差，这使得它能够在多个尺度上捕捉图像的细节。

与VDSR对比

- **网络结构**：VDSR是一个深度卷积网络，而DRCN是一个递归卷积网络。
- **参数数量**：由于权重共享，DRCN的参数数量比VDSR少。
- **残差学习**：尽管两者都使用残差学习，但DRCN在每个递归步骤中都学习残差，而VDSR则学习整体的残差。

**补充难点笔记：**

**在每个递归步骤中，网络的目标是学习和预测残差，这个残差表示当前的超分辨率输出与原始低分辨率图像之间的差异。具体来说：**

1. **初始步骤**：在DRCN的开始，原始的低分辨率图像首先通过嵌入网络（Embedding Network）进行处理，而不是直接上采样。这个嵌入网络的输出将被用作递归网络的输入。
2. **递归步骤**：在每个递归步骤中，网络确实是在学习和预测残差。但这个残差不是表示当前超分辨率输出与原始低分辨率图像之间的差异，而是表示当前输出与更高质量的超分辨率输出之间的差异。（**监督递归）**
3. **更新输出**：预测的残差被加到当前的输出上，生成一个新的输出。这个新的输出将被用作下一个递归步骤的输入。
4. **最终输出**：在所有递归步骤完成后，最后一个输出被传递到重建网络（Reconstruction Network），该网络生成最终的高分辨率输出。

通过这种方式，网络在每个递归步骤中都试图纠正其前一步的输出，使其更接近于真实的高分辨率图像。这种基于残差的递归方法允许网络更有效地捕捉和学习图像的细节和纹理。

总的来说，DRCN 是一个独特且高效的超分辨率模型，它通过递归的结构和权重共享来减少参数数量，同时保持了出色的性能。





###### **DRNN**

DRRN 是在DRCN的基础上引入了残差连接的改进版本，旨在解决深度网络训练中的梯度消失问题

1. **引入残差连接**：
   - DRRN 引入了残差连接（Residual Connection）的概念，这是其最显著的改进之一。在DRCN中，递归块之间的输出直接相加，使得每个递归步骤都负责学习图像的一部分内容。这样的设计有助于减轻梯度消失问题，允许更深的网络结构。
   - 残差连接的引入可以有效减少训练过程中的梯度退化问题，使得模型更容易训练。这对于深度学习模型的性能和收敛性都是有益的。
2. **端到端训练**：
   - DRRN 使用了端到端的训练方式，这意味着整个模型可以一次性进行训练，而不需要分阶段的递归训练。这简化了训练流程，使得模型更容易实现和优化。
   - 在DRCN中，训练过程需要迭代多次递归块，每个块都负责逐步提高图像的分辨率。而在DRRN中，通过残差连接，网络可以更好地在每个递归块之间传播信息。
3. **更深的网络**：
   - 由于引入了残差连接，DRRN允许构建更深的网络，这有助于更好地捕捉图像的细节和纹理。深层网络通常在超分辨率任务中表现更好。
   - DRCN也是一个深度网络，但它的训练和收敛可能会受到深度的限制，而DRRN的残差连接有助于解决这个问题。



###### **SRGAN/SRResNet**

尽管使用更快、更深的卷积神经网络在单幅图像的超分辨率方面取得了突破性的进展，但有一个核心问题在很大程度上仍未得到解决：**我们在大比例尺下进行超分辨率时，如何恢复更精细的纹理细节**？基于优化的超级分辨率方法的行为主要是由目标函数的选择所驱动。最近的工作主要集中在最小化平均平方重建误差上。由此产生的估计值具有较高的峰值信噪比（PSNR），但它们往往缺乏高频细节，并且在感知上不令人满意，在本文中，我们**提出了SRGAN，一个用于图像超分辨率（SR）的生成对抗网络（GAN）**,为了实现这一目标，我们**提出了一个由对抗性损失和内容损失组成的知觉损失函数**。



**卷积神经网络的设计**：越深的网络效果可能越好，但是训练比较困难，对此BN可以帮助有效训练更深的网络。残差块和跳连接也促进了超分辨的发展。此外上采样策略也是一个比较重要的网络设计方向。

**损失函数**：MSE 等像素损失难以处理恢复丢失的高频细节（如纹理）所固有的不确定性：最小化MSE鼓励寻找可信的解决方案的像素平均数，这些解决方案通常过于光滑，因此具有较差的感知质量。**GAN网络、VGG特征损失**等技术被提出用于解决该问题。



###### **EDSR**

EDSR是SSResnet的升级版，其对网络结构进行了优化(去除了BN层)，省下来的空间可以用于提升模型的size来增强表现力。此外，作者提出了一种基于EDSR且适用于多缩放尺度的超分结构——MDSR。



作者推出了一种加强版本的基于Resnet块的超分方法，它实际上是在SRResnet上的改进，去除了其中没必要的的BN部分，从而在节省下来的空间下扩展模型的size来增强表现力，它就是EDSR，其取得了当时SOAT的水平。
此外，作者在文中还介绍了一种**基于EDSR的多缩放尺度融合**在一起的新结构——MDSR。
EDSR、MDSR在2017年分别赢得了NTIRE2017超分辨率挑战赛的冠军和亚军。
此外，作者通过实验证明使用$L_{1}-Loss$比$L_{2}-Loss$具有更好的收敛特性。



###### **DenseNet**



###### **RDN**

#### 3.将SISR过程的性质与CNN框架的设计相结合:

在本小节中，我们将讨论一些深度框架，它们的架构或程序受到一些 SISR 代表性方法的启发。与上述面向 NN 的方法（以神经网络为中心的SISR方法）相比，这些方法可以更好地诠释 SISR，有时在处理某些具有挑战性的情况时也更为复杂。

##### 1.稀疏编码与深度神经网络的结合：

SCN（Sparse Coding  Network）是一种深度学习网络，通常用于特征提取和表示学习任务。SCN的主要思想受到了稀疏编码（Sparse  Coding）的启发，稀疏编码是一种经典的信号处理和特征学习技术，旨在将输入数据表示为一组基函数的线性组合，并使表示尽可能稀疏。**解决了传统稀疏编码 SISR 中耗时的推理问题。他们进一步推出了采用多个 SCN 的级联版本（CSCN）**

##### 2.通过神经网络进行集合学习：   

其中不同的模型专注于超分辨率图像的不同模式。

MSCN（Modulated Sub-networks for SISR），通过开发额外的卷积神经网络（CNN）模块，将低分辨率图像（LR）作为输入，输出与高分辨率图像（HR）相同形状的多个张量。

##### 3.采用渐进方法的深度架构：

主要讨论三种新颖方法：DEGREE、LapSRN和PixelSR。

- DEGREE利用ResNet的逐步特性和传统的子带重建方法相结合，使用递归残差块来重建高频细节。

- LapSRN逐步生成不同尺度的超分辨率图像：处理大尺度超分辨率重建（SISR）

- PixelSR则利用条件自回归模型逐像素生成超分辨率图像: 

  处理合理的细节合成的大尺度超分辨率问题 ，**PixelRNN  和 PixelCNN 是近期具有代表性的自回归生成模型**。

##### 4.具有反投影功能的深度架构

##### 5.使用LR的附加信息

1. DEGREE：DEGREE模型使用LR的边缘图作为额外的输入信息。这有助于模型更好地理解图像的边缘特征。
2. SFTGAN：SFTGAN使用LR的语义信息，以提高感知质量。它采用了语义分割图作为额外的输入信息，并使用了空间特征转换（SFT）层来处理这些信息。这有助于模型更好地生成图像的细节。
3. SRMD：SRMD模型将不同LR的退化信息直接整合到输入中。它使用参数化的零均值各向异性高斯核来表示模糊核，以及具有超参数ρ2的加性白高斯噪声。然后，通过简单的回归来获取协方差矩阵。这些足够的统计数据在通道维度上与LR连接，通过这样的输入来训练深度模型。这种方法允许模型考虑不同LR的降质情况，提高了重建的质量。



 

##### 6.具有内部示例的深度架构

当与核估计算法结合时，ZSSR在处理未知降级核的情况下表现良好。

#### 4.不同模式的比较与讨论

我们将从两个角度总结 SISR 深度架构的最新进展：**对特定模糊训练的定量比较，以及处理非特定模糊的模型的比较。**



##### 评价标准:

###### **MSE:均方误差**



###### **PSNR:峰值信噪比**



###### **SSIM:结构相似性指数**（亮度、对比度和结构）



##### 训练数据集对最终性能有很大影响：

###### 291 数据集

图像通常较小，图像分辨率有限，该数据集中的模型难以获得具有大感受野的大块图像。因此，基于 291 数据集的模型通常将 LR 的二次方作为输入，这相当耗时。

###### ImageNet数据集

图像要大得多

###### DIV2K 数据集

图像质量非常高

![img](C:\Users\Morty\Downloads\论文配图3.png)



### 四、制定有效的优化目标

#### 1.基于深度学习的SISR优化目标基准

##### 优化MSE（Mean Squared Error，均方误差）

MSE 是一种用于衡量预测值和真实值之间差异的度量。它计算了预测值和真实值之间差值的平方的平均值。在回归问题中，MSE常用于评估预测模型的准确性。较小的 MSE 值表示预测结果与真实值更接近。

##### MLE（Maximum Likelihood Estimation，最大似然估计）

MLE 是一种统计推断方法，用于估计概率分布的参数。它基于给定观测数据，寻找最有可能产生这些数据的参数值。MLE 假设观测数据是独立同分布的，并尝试找到最大化似然函数的参数值。最大似然估计在许多统计模型中广泛应用，例如线性回归、逻辑回归等。

##### KLD（Kullback-Leibler Divergence，Kullback-Leibler 散度）

KLD 是一种衡量两个概率分布之间差异的度量。它度量一个概率分布相对于另一个分布的信息损失或差异。KLD 值越小表示两个分布越接近，值越大表示差异越大。KLD 在信息论、概率论和机器学习中被广泛应用，例如在生成模型中用于衡量生成和真实分布之间的差异。

#### 2.基于非高斯加性噪声的目标函数

使用均方误差（MSE）优化的单图像超分辨率（SISR）图像在感知质量上表现较差，说明在高分辨率空间中使用高斯加性噪声不够理想。

##### MAE（平均绝对误差）

MAE在回归问题中被认为对异常值具有更强的鲁棒性，当用于优化神经网络（NN）时，NN更快地收敛并产生更好的结果。

##### 鲁棒统计学其他类似损失函数

鲁棒统计学中的其他类似损失函数可以用来建模其他概率分布的加性噪声，尽管这些特定分布可能不能精确表示未知的加性噪声，但在许多基于深度学习的SISR工作中，这些鲁棒统计损失函数因其简洁性和优势而被广泛使用。

##### 在变换空间中使用 MSE



#### 3.使用非参数估计优化前向 KLD

#### 4.不同目标函数的特征

在超分辨率中，有两种类型的损失函数：扭曲目标的损失和感知目标的损失。

##### 扭曲目标的损失函数：

基于衡量训练对的相似度。当训练数据不充足时，扭曲目标的损失往往忽视数据的特异性，无法有效地衡量源分布与目标分布之间的相似度。

##### 感知目标的损失函数：

基于衡量分布之间的相似度，被认为可以度量感知质量。感知目标的损失是通过衡量分布之间的相似度来度量感知质量。使用这种损失可以在一定程度上提高超分辨率图像的质量。

**二者不可得兼**

研究表明，扭曲目标的损失和感知目标的损失之间存在固有的权衡关系。通过优化问题可以看出，改善其中一个目标必然会以另一个目标为代价



### 五、发展趋势与挑战

#### 两大挑战

##### 1.设计轻量化的深度模型：

设计轻量化的深度模型，以减少参数和计算量，提高模型在实际场景中的部署效率。

##### 2.开发更有效的深度学习算法

开发更有效的深度学习算法来应对大规模SISR和未知损坏的情况。

#### 发展趋势

##### 1.加深深度学习模型的理解

加强对深度模型在SISR中的理论理解，探索学习到的表示和深度架构的内在机制，而不仅仅关注模型的表现。

##### 2.制定更合适的评估标准

在不同应用中制定更合理的SISR评估标准，避免简单地使用均方误差（MSE）作为唯一的衡量标准，根据应用的需求定义明确的评估指标。

